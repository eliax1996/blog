+++
title = 'What I did from June 2023 to March 2024 - my MATS experience'
date = 2024-03-20T16:37:36+08:00
draft = false
+++


This post may be interesting for people who
- are interested in getting into AI alignment / the MATS program
- are interested in how I benefited / grew in the period

Background

In 2023 I was working as a machine learning engineer. I wanted to work on AI alignment problems. I quit my job and participated in the MATS Summer 2023 program. The [MATS program](https://www.matsprogram.org) puts you together with others to work on AI alignment problems under a specific mentor. 
I was under Ethan's Perez stream where we worked on improving Chain of Thought transparency. I started in June 2023, and continued until ~March 2024 under the extension program, until my [paper was submitted.](https://arxiv.org/abs/2403.05518)



## Tangible outcomes
One tangible outcome was that I co-wrote a paper for submission to a conference.  Before MATS, I was a machine learning engineer, without any publications, and was looking for an alignment related job. I got rejected from all organizations I applied for. I don't think having a paper is an absolute must - I was at least able to get past resume screening for a few alignment organisations before joining MATS. Still, I think that writing a paper has showed that I am capable of working on research, to increase my chances of getting hired as a research engineer. Counterfactual thought - I think that without MATS, it would be much harder for me to have published anything. Being someone outside academia, and not working in an organization that publishes research, I struggle to think of how I would have gotten the opportunity to write a paper, so I really appreciate MATS for that.

In terms of technical skills, I learnt productivity and coding tricks from my co-author Edward Rees. He taught me many terminal / vim tricks to help me become a 2X engineer. We also had to implement a whole bunch of language model evaluations (evals), which made me learn the pain of managing many different types of evals. Pair programming with him was really fun.


## Soft skills
I think a big part of what I took away was more on the intangible side of soft skills. I did not expect this to be the case before joining MATS, but looking back I really appreciate it. During MATS, you'll have access to Scholar Support - think of it as a coach that helps you with your personal development. Some things that I've learnt from them are:
- How to tackle the planning fallacy. For example, if I aimed to have a draft out by friday, I would ask myself "Would I be surprised if on Saturday, I still didn't have the draft out". Most of the time, I wouldn't be that surprised if I did not reach my goal on time. This question helped me to identify areas that I needed to address first.
- How to tackle procrastination. It turns out that I procastinate when one side of myself really wants to do something, but the other side thinks doing that thing is dumb. I did some [Internal Double Crux](https://www.lesswrong.com/tag/internal-double-crux) sessions - to resolve disagreements between my two selves. It helped me with my motivation to write the paper, and to do things like leetcode for 
- How to resolve disagreements. I think that before MATS, my style of resolving disagreements was to try to persuade the other person to my point of view, but that could lead to a lot of frustration. I learnt that when disagreeing, it is better to try to fully understand the other person's point of view. Keep asking and digging deeper into their point of view to understand their mental model, rather than to try and persuade them. This helps you two to converge faster to a common understanding.

I also learnt how to communicate my ideas better. I had to make slides for my weekly meetings with Ethan. At the start, my slides were quite poor, but I got better at it over time. Showing my slides before my weekly meetings to my stream mates helped me to communicate my ideas better.

I think that I've developed a philosophy of how to research something - do the minimal thing that will update your beliefs the most. For example, Ethan suggested that we can few-shot a model as a proxy for fine-tuning it. You few-shot a model much faster than finetuning - and that gives us a fast clue of whether optimizing a model for a certain thing will work. I also trained my sense of what experiments to run next -  I think that by the end of MATS, I had a distilled model of Ethan's feedback in my head, which told me what kind of experiments he was looking for in my weekly meetings. 

Making friends / networking. Being from Singapore, where there are not many people working on AI alignment, I really appreciated the opportunity to make friend and meet with people who are also interested in AI alignment. For example, I worked with Miles Turpin - who was our mentor as well - and he gave us so much help in our research direction. From him, I learnt what kind of alignment research was interesting and impactful to other researchers.

<!-- Softskills - Comunication, making slides. Rob Miles gave a talk about why communication is so important. In the end, we probably won't be in the room where AGI gets invented. If we want to influence the development of safe AGI, we need to publish research that actually influences the people who invent AGI. We want them to read our research. That means writing and conveying our ideas well.  -->

<!-- Soft-skills Scholar support tricks. I had and have issues with the planning fallacy, procrastination and motivation. For example, I dislike writing and leetcode.  -->

 <!-- "Would you be surprised if you didn't actually complete this on time". When disagreeing with someone, try to fully understand their point of view. Keep asking and digging deeper into their point of view to understand their mental model. -->

<!-- trained my sense of what experiments to run next. At the end of serimats I felt like i had a good internal version of ethan-haiku that would tell me what ethan was looking for in my weekly meetings. -->

<!-- Geographical distance. network

friends.

Writing a paper. 

Evals being painful. -->



<!-- Tips for those working on MATs projects

Pair programming
Be clear about how long everyone can / expect each other to commit. I think joining SERIMATs and early on in the project, on I thought that we would finish sometime in early january, so had made plans based on that. Miles (from what I understand) expected that we’ll probably finish in february ++ after writing. When I realised that the project would probably get delayed to feb ++ back in december, I felt stressed about it because of the rescheduling of plans. I feel that if we (all team members) communicated early on when we expected to finish, when we can commit until, could have made planning and scheduling easier. So takeaway for future projects could be telling scholars that “don’t expect to finish on time”.
Sharing motivations / aims. This may be hard depending on how vulnerable we can be. E.g. For me, I feel like writing a B+ paper is good enough (80-20) in terms of giving me research experience, looking nice on my resume, and contributing to alignment. On the other hand, if the research I’ve done was not high quality enough, and led to making only an alignment forum post instead, it would have been more disappointing. Yet, making a A+ paper (like making sure it would be top tier conference quality) feels less efficient to me in terms of time spent (in terms of impact in my area + actual research output). I think sharing motivations early on can help align expectations of how much time / effort we want to put in. E.g. early on I was quite sceptical of having to submit to a conference, because I was sceptical about what we were going to get out of it, in exchange for the effort spent. Miles did tell me that sharing alignment research on a peer reviewed channel helps communicate our ideas in a much wider audience, which I now agree with. Although if I did another round of SERIMATs, now that I already have written a paper, that is sufficient for my career capital. I may infact try the alignment forum route (lol), because I feel that its a much faster route of getting public feedback / communicating results? Like maybe could get a post out in 2 months rather than 6+ months. I feel that time taken is important to consider, because I feel like sometimes the next iteration of models just makes everything obselete? Takeaway: Get teammates to say what they want out of the project.
Sequentially commiting. -->





